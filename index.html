<!doctype html>
<html lang="en" class="no-js">

<head>
    <meta charset="utf-8"> <!-- begin SEO -->
    <title> Canyu Chen‚Äôs Homepage</title>
    <meta property="og:locale" content="en-US">
    <meta property="og:site_name" content="Canyu Chen's Homepage">
    <meta property="og:title" content="Canyu Chen‚Äôs Homepage">
    <link rel="canonical" href="https://canyuchen.com/">
    <meta property="og:url" content="https://canyuchen.com/">
    <meta property="og:description" content="About me">
    <script
        type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Canyu Chen", "url" : "https://canyuchen.com", "sameAs" : null } </script>
    <!-- end SEO -->
    <link href="https://yueqingliang1.github.io/feed.xml" type="application/atom+xml" rel="alternate"
        title="Canyu Chen's Homepage Feed"> <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script>
    <!-- For all browsers -->
    <link rel="stylesheet" href="https://yueqingliang1.github.io/assets/css/main.css">
    <meta http-equiv="cleartype" content="on"> <!-- start custom head snippets -->
    <link rel="apple-touch-icon" sizes="57x57"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="60x60"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="72x72"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="76x76"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="114x114"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="120x120"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="144x144"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="152x152"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
    <link rel="apple-touch-icon" sizes="180x180"
        href="https://yueqingliang1.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
    <link rel="icon" type="image/png" href="https://yueqingliang1.github.io/images/favicon-32x32.png?v=M44lzPylqQ"
        sizes="32x32">
    <link rel="icon" type="image/png"
        href="https://yueqingliang1.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
    <link rel="icon" type="image/png" href="https://yueqingliang1.github.io/images/favicon-96x96.png?v=M44lzPylqQ"
        sizes="96x96">
    <link rel="icon" type="image/png" href="https://yueqingliang1.github.io/images/favicon-16x16.png?v=M44lzPylqQ"
        sizes="16x16">
    <link rel="manifest" href="https://yueqingliang1.github.io/images/manifest.json?v=M44lzPylqQ">
    <link rel="mask-icon" href="https://yueqingliang1.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ"
        color="#000000">
    <link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage"
        content="https://yueqingliang1.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
    <meta name="msapplication-config" content="https://yueqingliang1.github.io/images/browserconfig.xml?v=M44lzPylqQ">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="https://yueqingliang1.github.io/assets/css/academicons.css" />
    <script
        type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
    <script
        type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
    <!-- end custom head snippets -->
</head>

<body>
    <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->
    <div class="masthead">
        <div class="masthead__inner-wrap">
            <div class="masthead__menu">
                <nav id="site-nav" class="greedy-nav"> <button>
                        <div class="navicon"></div>
                    </button>
                    <ul class="visible-links">
                        <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://canyuchen.com/">Canyu
                                Chen's Homepage</a></li>
                    </ul>
                    <ul class="hidden-links hidden"></ul>
                </nav>
            </div>
        </div>
    </div>
    <div id="main" role="main">
        <div class="sidebar sticky">
            <div itemscope itemtype="http://schema.org/Person">
                <div class="author__avatar"> <img src="images/me_4.jpeg" class="author__avatar" alt="Canyu Chen"></div>
                <div class="author__content">
                    <h3 class="author__name"> Canyu Chen </h3>
                    <p class="author__bio">Ph.D. student at Illinois Institute of Technology</p>
                </div>
                <div class="author__urls-wrapper"> <button class="btn btn--inverse">Follow</button>
                    <ul class="author__urls social-icons">
                        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Chicago, Illinois</li>
                        <li><a href="mailto:cchen151@hawk.iit.edu"><i class="fas fa-fw fa-envelope"
                                    aria-hidden="true"></i> Email</a></li>
                        <li><a href="https://twitter.com/CanyuChen3"><i class="fab fa-fw fa-twitter"
                                    aria-hidden="true"></i> Twitter</a></li>
                        <li><a href="https://www.linkedin.com/in/canyu-chen-1b2415100/"><i class="fab fa-fw fa-linkedin"
                                    aria-hidden="true"></i> LinkedIn</a></li>
                        <li><a href="https://github.com/canyuchen"><i class="fab fa-fw fa-github"
                                    aria-hidden="true"></i> Github</a></li>
                        <li><a
                                href="https://scholar.google.com/citations?hl=en&user=iKfWNy0AAAAJ&view_op=list_works&sortby=pubdate"><i
                                    class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
                        <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=DzVxbNa1d5i0c4qQ0vv5ZYvcMVszZxDHALZxQhrnUuQ&cl=ffffff&w=a"></script> -->
                    </ul>
                </div>
            </div>
        </div>
        <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
            <div class="page__inner-wrap">
                <section class="page__content" itemprop="text">
                    <p>Hi, this is Canyu Chen (ÈôàÁÅøÂÆá), a third-year Computer Science
                        Ph.D. student at <em>Illinois Institute of Technology
                            (IIT)</em>
                        since Fall 2021, advised by <a href="http://www.cs.iit.edu/~kshu/">Prof. Kai Shu</a>. Before
                        joining IIT, I received my <em>B.S.</em> in Computer Science from the <em>
                            University of Chinese Academy of Sciences (UCAS)
                        </em> in 2020.</p>

                    <p>I focus on <strong>Truthful, Safe and Responsible Large Language Models</strong> with
                        the applications in
                        <strong>Social Computing and Healthcare</strong>. I have started and currently lead the <em><strong><a
                                    href="https://llm-misinformation.github.io/">LLMs Meet
                                    Misinformation</a></strong></em> initiative, aiming to combat misinformation in the age of LLMs. I aim to pursue <strong>Safe and Aligned Artificial General Intelligence</strong> in the long run.
                        I am always happy to chat and discuss potential collaborations (email: cchen151 AT hawk.iit.edu, wechat ID: alexccychen).
                    </p>
                    <h2 id="news">News</h2>
                    <!-- <h3 id="news">News</h3> -->
                    <div class="highlight">
                        <!-- <pre> -->
                        <ul>
                            <li>[03/2024] Deeply honored and humbled to receive the prestigious üèÜ <a href="https://www.iit.edu/grant-writing-resources-and-funding-opportunities/funding-opportunities/winners-sigma-xi" style="text-decoration:none"><strong><font color="red">Sigma Xi Student Research Award 2024</font></strong></a> from Illinois Tech and the local Sigma Xi chapter.</li>
                            <li>[02/2024] New preprint is online <a href="https://arxiv.org/abs/2402.04559">Can Large Language Model Agents Simulate Human Trust Behaviors?</a>, <a href="https://www.camel-ai.org/research/agent-trust">[project website]</a> Code and results have been released for verification. <a href="https://github.com/camel-ai/agent-trust">[code and results]</a> Demos on HuggingFace: <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Trust-Game-Demo">[Trust Game Demo]</a>
                                <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Repeated-trust-game-Demo">[Repeated Trust Game Demo]</a>.</li>
                            <li>[01/2024] <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a> is accepted to <em><b>ICLR 2024</b></em>, <a href="https://llm-misinformation.github.io/">[project website]</a> <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and code]</a>.</li>
                            <li>[12/2023] Honored to receive üèÜ <a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><strong><font color="red">Didactic Paper Award</font></a> </strong> (1/35 of all accepted papers) in workshop <em><b><a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><font color="#494e52">ICBINB@NeurIPS 2023</font></a></b></em> for <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>.</li>
                            <li>[10/2023] Start an initiative <em><strong><a href="https://llm-misinformation.github.io/">LLMs Meet Misinformation</a></strong></em> along with a new survey paper <a href="https://arxiv.org/abs/2311.05656">Combating Misinformation in the Age of LLMs: Opportunities and Challenges</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>  and a paper list collecting related papers and resources <a href="https://github.com/llm-misinformation/llm-misinformation-survey">[paper list]</a>.</li>
                            <li>[10/2023] Honored to be covered by Illinois Tech News on the research of Trustworthy AI, <a href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[IIT News]</a>.</li>
                            <li>[09/2023] New preprint is online <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>. The dataset and code are released <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and code]</a>.</li>
                            <!-- <li>[10/2023] New survey paper <a href="https://llm-misinformation.github.io/static/pdf/Combating%20Misinformation%20in%20the%20Age%20of%20LLMs:%20Opportunities%20and%20Challenges.pdf">Combating Misinformation in the Age of LLMs: Opportunities and Challenges</a>, <a href="https://llm-misinformation.github.io/">[project website]</a></li>
                            <li>[10/2023] Honored to be covered by Illinois Tech News on research of Trustworthy AI, <a href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[IIT News]</a></li>
                            <li>[09/2023] New preprint <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>, <a href="https://llm-misinformation.github.io/">[project website]</a></li> -->
                            <!-- <li>[06/2023] Will attend <a href="https://facctconference.org/2023/">FAccT 2023</a> as a volunteer. Welcome to Chicago and glad to connect!</li>
                            <li>[05/2023] One paper accepted at <a href="https://2023.eacl.org/">EACL 2023</a> and will attend online. Welcome to our poster!</li>
                            <li>[04/2023] Glad to be invited by Prof. <a href="https://lucheng.ml/">Lu Cheng</a> to give a talk on AI Fairness at UIC <a href="https://drive.google.com/file/d/1U9CkO_nOTKDJP1DycKrYW2r0IugXLjqh/view?usp=sharing">[Slides]</a></li>
                            <li>[11/2022] Attend <a href="https://nips.cc/">NeurIPS 2022</a> in person. See you at New Orleans!</li>
                            <li>[08/2022] Attend <a href="https://kdd.org/kdd2022/">KDD 2022</a> in person. Glad to meet old friends and make new friends!</li> -->
                            <!-- </pre> -->
                        </ul>
                        <details>
                        <summary><b>Older News</b></summary>
                        <ul>
                            <!-- <li>[02/2024] New preprint is online <a href="https://arxiv.org/abs/2402.04559">Can Large Language Model Agents Simulate Human Trust Behaviors?</a>, <a href="https://www.camel-ai.org/research/agent-trust">[project website]</a> Code and results have been released for verification. <a href="https://github.com/camel-ai/agent-trust">[code and results]</a> Demos on HuggingFace: <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Trust-Game-Demo">[Trust Game Demo]</a>
                                <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Repeated-trust-game-Demo">[Repeated Trust Game Demo]</a>.</li>
                            <li>[01/2024] <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a> is accepted to <em><b>ICLR 2024</b></em>, <a href="https://llm-misinformation.github.io/">[project website]</a> <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and code]</a>.</li>
                            <li>[12/2023] Honored to receive üèÜ <a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><strong><font color="red">Didactic Paper Award</font></a> </strong> (1/35 of all accepted papers) in workshop <em><b><a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><font color="#494e52">ICBINB@NeurIPS 2023</font></a></b></em> for <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>.</li>
                            <li>[10/2023] Start an initiative <em><strong><a href="https://llm-misinformation.github.io/">LLMs Meet Misinformation</a></strong></em> along with a new survey paper <a href="https://arxiv.org/abs/2311.05656">Combating Misinformation in the Age of LLMs: Opportunities and Challenges</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>  and a paper list collecting related papers and resources <a href="https://github.com/llm-misinformation/llm-misinformation-survey">[paper list]</a>.</li>
                            <li>[10/2023] Honored to be covered by Illinois Tech News on the research of Trustworthy AI, <a href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[IIT News]</a>.</li>
                            <li>[09/2023] New preprint is online <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>. The dataset and code are released <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and code]</a>.</li> -->
                            <!-- <li>[10/2023] New survey paper <a href="https://llm-misinformation.github.io/static/pdf/Combating%20Misinformation%20in%20the%20Age%20of%20LLMs:%20Opportunities%20and%20Challenges.pdf">Combating Misinformation in the Age of LLMs: Opportunities and Challenges</a>, <a href="https://llm-misinformation.github.io/">[project website]</a></li>-->
                            <!-- <li>[10/2023] Honored to be covered by Illinois Tech News on research of Trustworthy AI, <a href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[IIT News]</a></li>
                            <li>[09/2023] New preprint <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>, <a href="https://llm-misinformation.github.io/">[project website]</a></li>  -->
                            <li>[06/2023] Will attend <a href="https://facctconference.org/2023/">FAccT 2023</a> as a volunteer. Welcome to Chicago and glad to connect!</li> 
                            <li>[05/2023] One paper accepted at <a href="https://2023.eacl.org/">EACL 2023</a> and will attend online. Welcome to our poster!</li>
                            <li>[04/2023] Glad to be invited by Prof. <a href="https://lucheng.ml/">Lu Cheng</a> to give a talk on AI Fairness at UIC <a href="https://drive.google.com/file/d/1U9CkO_nOTKDJP1DycKrYW2r0IugXLjqh/view?usp=sharing">[Slides]</a></li>
                            <li>[11/2022] Attend <a href="https://nips.cc/">NeurIPS 2022</a> in person. See you at New Orleans!</li>
                            <li>[08/2022] Attend <a href="https://kdd.org/kdd2022/">KDD 2022</a> in person. Glad to meet old friends and make new friends!</li> 
                            <!-- </pre> -->
                        </ul>
                        </details>
                    </div>
                    <!-- <h2 id="news">News</h2>
                    <ul>
                        <li>[01/2024] <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a> is accepted to <em><b>ICLR 2024</b></em>, <a href="https://llm-misinformation.github.io/">[project website]</a> <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and
                            code]</a>.</li>
                        <li>[12/2023] Honored to receive üèÜ <a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><strong><font color="red">Didactic Paper Award</font></a> 
                        </strong> (1/35 of all accepted papers) in workshop <em><b>ICBINB@NeurIPS 2023</b></em> for <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>.</li>
                        <li>[10/2023] Start an initiative <em><strong><a
                            href="https://llm-misinformation.github.io/">LLMs Meet
                            Misinformation</a></strong></em> along with a new survey paper <a href="https://arxiv.org/abs/2311.05656">Combating Misinformation in the Age of LLMs: Opportunities and Challenges</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>  and a paper list collecting related papers and resources <a href="https://github.com/llm-misinformation/llm-misinformation-survey">[paper
                                list]</a>.</li>
                        <li>[10/2023] Honored to be covered by Illinois Tech News on the research of Trustworthy AI, <a href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[IIT News]</a>.</li>
                        <li>[09/2023] New preprint is online <a href="https://arxiv.org/abs/2309.13788">Can LLM-Generated Misinformation Be Detected?</a>, <a href="https://llm-misinformation.github.io/">[project website]</a>. The dataset and code are released <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and
                            code]</a>.</li>
                    </ul> -->
                    <h2 id="publications">Publications</h2>
                    <h3 id="2023">2024</h3>
                    <ul>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2402.04559" style="text-decoration:none"><font color="#494e52">Can Large Language Model Agents Simulate Human Trust Behaviors?</font></a></strong>
                                <br /> <a href="https://yitianlian.github.io/">Chengxing Xie</a>*, <strong>Canyu Chen</strong>*, <a href="https://feiran.io/">Feiran Jia</a>, <a href="https://ziyu-deep.github.io/">Ziyu Ye</a>, <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>, <a href="https://www.adelbibi.com/">Adel Bibi</a>, <a href="https://acbull.github.io/">Ziniu Hu</a>, <a href="https://www.robots.ox.ac.uk/~phst/">Philip Torr</a>, <a href="https://www.bernardghanem.com/">Bernard Ghanem</a>, <a href="https://ghli.org/">Guohao Li</a>. (*equal contributions)
                                <br /> <em>Workshop in The Twelfth International Conference on Learning Representations
                                    <!-- workshop on Efficient Natural Language and Speech Processing (<strong><a href="https://neurips2022-enlsp.github.io/"><font color="#494e52">ENLSP@NeurIPS 2022</font></a></strong>, <b><font color="red">Oral (spotlight)</font></b>)</em>. -->
                                     ( <strong><a href="https://agiworkshop.github.io/" style="text-decoration:none"><font color="#494e52">AGI@ICLR 2024</font></a></strong> )</em>.
                                     <br /> <em>Seventeenth Midwest Speech and Language Days
                                     (<strong>
                                        <a href="https://ai.engin.umich.edu/news/midwest-speech-and-language-days/" style="text-decoration:none"><font color="#494e52">MSLD 2024</font></a></strong>, <b>
                                        <font color="red">Oral</font>
                                    </b>)</em>.
                                <br /> <a href="https://arxiv.org/abs/2402.04559">[arXiv]</a>
                                <a href="https://www.camel-ai.org/research/agent-trust">[project website]</a>
                                <a href="https://github.com/camel-ai/agent-trust">[code and results]</a>
                                <br />Demos on HuggingFace:
                                <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Trust-Game-Demo">[Trust Game Demo]</a>
                                <a href="https://huggingface.co/spaces/camel-ai/agent-trust-Repeated-trust-game-Demo">[Repeated Trust Game Demo]</a>
                                <!-- <a href="">[demo]</a> -->

                            </p>
                        </li>
                        
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2309.13788" style="text-decoration:none"><font color="#494e52">Can LLM-Generated Misinformation Be Detected?</font></a></strong>
                                <br /><strong>Canyu Chen</strong>,
                                <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <!-- <br /> arXiv preprint. Sept. 2023. -->
                                <br /> <em>Proceedings of The Twelfth International Conference on Learning Representations (<strong>
                                        <font color="#494e52">ICLR 2024</font></strong> )</em>
                                <br /> <em>Workshop in the 37th Conference on Neural Information Processing Systems
                                    <!-- workshop on Efficient Natural Language and Speech Processing (<strong><a href="https://neurips2022-enlsp.github.io/"><font color="#494e52">ENLSP@NeurIPS 2022</font></a></strong>, <b><font color="red">Oral (spotlight)</font></b>)</em>. -->
                                     (<strong>
                                        <a href="https://regulatableml.github.io/" style="text-decoration:none"><font color="#494e52">RegML@NeurIPS 2023</font></a></strong>, <b>
                                        <font color="red">Oral</font>
                                    </b> and <strong>
                                        <a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><font color="#494e52">ICBINB@NeurIPS 2023</font></a></strong>, <b>
                                        <font color="red">spotlight</font>
                                    </b>)</em>.
                                    <br /> <a href="https://arxiv.org/abs/2309.13788">[arXiv]</a>
                                    <a href="https://llm-misinformation.github.io/">[project website]</a>
                                    <a href="https://github.com/llm-misinformation/llm-misinformation/">[dataset and code]</a>
                                    <a href="https://zhuanlan.zhihu.com/p/678425256">[zhihu]</a>
                                    <a href="https://x.com/CanyuChen3/status/1749337997340790955?s=20">[twitter/x.com]</a>
                                    <a href="https://www.linkedin.com/posts/canyu-chen-1b2415100_iclr2024-misinformation-llm-activity-7155088736353972224--5Ng?utm_source=share&utm_medium=member_desktop">[LinkedIn]</a>
    
                                <br /> <strong>
                                    <font color="#3b5af2">Included in the curriculum at:</font>
                                </strong>  <a
                                    href="https://github.com/michellejm/LLMs-fall-23">[The University of New York]</a>.
                                <br /> <strong>
                                    <font color="#3b5af2">üèÜ Award:</font> <a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><font color="red">Didactic Paper Award</font></a>
                                </strong> in the workshop <em><b><a href="https://sites.google.com/view/icbinb-2023/papers?authuser=0" style="text-decoration:none"><font color="#494e52">ICBINB@NeurIPS 2023</font></a></b> (1/35 of all accepted papers).</em>
                                <br /> <strong>
                                    <font color="#3b5af2">üèÜ Award:</font> <a href="https://drive.google.com/file/d/1sqfVrGz7lYjQQiMNFyRNAeYINr4fzGCT/view?usp=sharing" style="text-decoration:none"><font color="red">Third Place Award</font></a>
                                </strong> in the <em><b><a href="https://drive.google.com/file/d/1sqfVrGz7lYjQQiMNFyRNAeYINr4fzGCT/view?usp=sharing" style="text-decoration:none"><font color="#494e52">Illinois Tech College of Computing Poster Session 2024 (Ph.D. Group)</font></a></b>.</em>
                                <br /> <strong>
                                    <font color="#3b5af2">Media Coverage</font>
                                </strong> : 
                                <a href="https://www.theregister.com/2024/01/30/llms_misinformation_human/">[The Register]</a>
                                <a href="https://www.analyticsvidhya.com/blog/2024/02/are-llms-outsmarting-humans-in-crafting-persuasive-misinformation/">[Analytics Vidhya Blog]</a>
                                <a href="https://www.linkedin.com/pulse/business-keeping-internet-safe-jooho-yeo-fzpzf/?trackingId=Frm6xc2CSJyyBoHSFGDVUQ%3D%3D">[Another Blog]</a>.
                                <br /> <strong>
                                    <font color="#3b5af2">Invited Talks</font>
                                </strong> : 
                                <a href="https://superagi.com/wp-content/uploads/2024/02/AGI-Leap-Summit-Schedule.pdf">[AGI Leap Summit Spoltlight Research]</a>
                                <a href="https://mp.weixin.qq.com/s/kxulG-96cJWv_5GyG4-2qw">[Tsinghua AI Time]</a>
                                <a href="https://mp.weixin.qq.com/s/nZgzQzvaVda1fLTXn1YAzQ">[Psych Methods]</a>.

                            </p>
                        </li>

                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2403.08213" style="text-decoration:none"><font color="#494e52">Can Large Language Models Identify Authorship?</font></a></strong>
                                <br /> <a href="https://baixianghuang.github.io/">Baixiang Huang</a>, <strong>Canyu Chen</strong>, <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> arXiv preprint. Mar. 2024.
                                <br /> <a href="https://arxiv.org/abs/2403.08213">[arXiv]</a>
                                <a href="https://github.com/baixianghuang/authorship-llm">[code]</a>
                            </p>
                        </li>
                        

                    </ul>
                    <h3 id="2023">2023</h3>
                    <ul>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2311.05656" style="text-decoration:none"><font color="#494e52">Combating Misinformation in the Age of LLMs: Opportunities and
                                    Challenges</font></a></strong>
                                <br /><strong>Canyu Chen</strong>,
                                <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> arXiv preprint. Oct. 2023.
                                <br /> <a href="https://arxiv.org/abs/2311.05656">[arXiv]</a>
                                <a href="https://llm-misinformation.github.io/">[project website]</a>
                                <a href="https://github.com/llm-misinformation/llm-misinformation-survey">[paper
                                    list]</a>
                                <br /> <strong>
                                    <font color="#3b5af2">Media Coverage</font>
                                </strong> : 
                                <a href="https://www.marktechpost.com/2024/01/27/this-ai-report-from-the-illinois-institute-of-technology-presents-opportunities-and-challenges-of-combating-misinformation-with-llms/">[Marktechpost AI Research News]</a> 
                                <a href="https://www.reddit.com/r/machinelearningnews/comments/1acbgti/this_ai_report_from_the_illinois_institute_of/">[Reddit r/machinelearningnews]</a>
                                <a href="https://www.analyticsvidhya.com/blog/2024/02/are-llms-outsmarting-humans-in-crafting-persuasive-misinformation/">[Analytics Vidhya Blog]</a>.
                                <br /> <strong>
                                    <font color="#3b5af2">Invited Talks</font>
                                </strong> : 
                                <a href="https://mp.weixin.qq.com/s/nZgzQzvaVda1fLTXn1YAzQ">[Psych Methods]</a>.
                                <br />
                            </p>
                        </li>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2205.09229" style="text-decoration:none"><font color="#494e52">PromptDA: Label-guided Data Augmentation for Prompt-based Few-shot
                                    Learners.</font></a></strong>
                                <br /><strong>Canyu Chen</strong>,
                                <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> <em>Proceedings of the 17th Conference of the European Chapter of the Association
                                    for Computational Linguistics (<strong>
                                        <font color="#494e52">EACL 2023</font></strong>, Main Conference Long Paper)</em>
                                <br /> <em>Workshop in the 36th Conference on Neural Information Processing Systems ( <strong>
                                    <a href="https://neurips2022-enlsp.github.io/" style="text-decoration:none"><font color="#494e52">ENLSP@NeurIPS 2022</font></a></strong>, <b>
                                        <font color="red">Oral (spotlight)</font>
                                    </b>)</em>.
                                <br />
                                <a href="https://arxiv.org/abs/2205.09229">[arXiv]</a>
                                <a href="https://github.com/canyuchen/PromptDA">[code]</a>
                                <a href="https://www.youtube.com/watch?v=f6Jh7BIMtWw">[youtube]</a>
                                <a href="https://www.bilibili.com/video/BV1Zm4y127ck">[bilibili]</a>
                                <a
                                    href="https://drive.google.com/file/d/1BqC1ge1n6iNYxpN81qQT9hdjHLuQz_bn/view?usp=sharing">[slides]</a>
                                <a
                                    href="https://drive.google.com/file/d/11z-41wLJLdtmEMin9LnpzD63PhW27vBm/view?usp=sharing">[poster]</a>
                                <!-- <a href="https://drive.google.com/file/d/1kh5kpSQ1I-06cYagcAr_wjYljMfZsqM_/view?usp=share_link">[workshop version]</a> -->
                            </p>
                        </li>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2206.03656" style="text-decoration:none"><font color="#494e52">Fair Classification via Domain Adaptation: A Dual Adversarial Learning
                                    Approach.</font></a></strong><br />
                                <a href="https://yueqingliang1.github.io/">Yueqing Liang</a>, <strong>Canyu
                                    Chen</strong>, <a href="https://www.linkedin.com/in/tian-tian-3b0a9bb0/">Tian
                                    Tian</a>, <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> <strong><em>
                                        <font color="#494e52">Frontiers in Big Data 2023</font>
                                    </em></strong>.<br />
                                <a href="https://www.frontiersin.org/articles/10.3389/fdata.2022.1049565/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Big_Data&id=1049565">[paper]</a>
                                <a href="https://arxiv.org/abs/2206.03656">[arXiv]</a>
                            </p>
                        </li>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2302.07363" style="text-decoration:none"><font color="#494e52">Attacking Fake News Detectors via Manipulating News Social Engagement.</font></a></strong>
                                <br /><a href="https://brucehrwang.com/academic/home">Haoran Wang</a>, <a
                                    href="https://brucehrwang.com/academic/home">Yingtong Dou</a>, <strong>Canyu
                                    Chen</strong>, <a href="https://lichao-sun.github.io/">Lichao Sun</a>, Philip S. Yu,
                                <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> <em>Proceedings of The ACM Web Conference 2023 (<strong>
                                        <font color="#494e52">WWW 2023</font>
                                    </strong>).</em>
                                    <br />
                                    <a href="https://arxiv.org/abs/2302.07363">[arXiv]</a>
                                    <a href="https://github.com/hwang219/AttackFakeNews">[code]</a>
                                <br /> <strong>
                                    <font color="#3b5af2">Media Coverage</font>
                                </strong> : <a
                                    href="https://montrealethics.ai/attacking-fake-news-detectors-via-manipulating-news-social-engagement/">[Montreal
                                    AI Ethics Institute]</a>.</em>
                            </p>
                        </li>
                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2305.10668" style="text-decoration:none"><font color="#494e52">MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection.</font></a></strong>
                                <br /><a href="https://xiongxiaoxu.github.io/">Xiongxiao Xu</a>, <a
                                    href="https://kaize0409.github.io/">Kaize Ding</a>, <strong>Canyu Chen</strong>,
                                <a href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> arXiv preprint. May. 2023.
                                <br /> <a href="https://arxiv.org/abs/2305.10668">[arXiv]</a>
                            </p>
                        </li>
                        <!-- <li>
                            <p><strong>PyGOD: A Python Library for Graph Outlier Detection.</strong><br />
                                Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang, Kaize Ding,
                                <strong>Canyu Chen</strong>, Hao Peng, George H. Chen, Zhihao Jia, Philip S.
                                Yu.
                                <br /><em>Journal of Machine Learning Research (<strong>
                                        <font color="#494e52">JMLR 2023</font>
                                    </strong>)</em>.<br /> <a href="https://github.com/pygod-team/pygod">[code]</a>
                                <a href="https://arxiv.org/abs/2204.12095">[arXiv]</a>
                            </p>
                        </li> -->

                    </ul>
                    <h3 id="2022">2022</h3>
                    <ul>


                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2211.05289" style="text-decoration:none"><font color="#494e52">Combating Health Misinformation in Social Media: Characterization, Detection,
                                    Intervention, and Open Issues.</font></a></strong><br />
                                <strong>Canyu Chen*</strong>, <a href="https://brucehrwang.com/academic/home">Haoran
                                    Wang</a>*, <a href="https://understandgreen.com/">Matthew Shapiro</a>, <a
                                    href="https://vivo.weill.cornell.edu/display/cwid-yux4008">Yunyu Xiao</a>, <a
                                    href="https://wcm-wanglab.github.io/">Fei Wang</a>, <a
                                    href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>. (*equal contributions)
                                <br /> arXiv preprint. Nov. 2022.
                                <br /> <a href="https://arxiv.org/abs/2211.05289">[arXiv]</a>
                            </p>
                        </li>

                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2207.08336" style="text-decoration:none"><font color="#494e52">When Fairness Meets Privacy: Fair Classification with Semi-Private Sensitive
                                    Attributes.</font></a></strong><br />
                                <strong>Canyu Chen</strong>, <a href="https://yueqingliang1.github.io/">Yueqing
                                    Liang</a>, <a href="https://xiongxiaoxu.github.io/">Xiongxiao Xu</a>, <a
                                    href="https://scholar.google.com/citations?user=fZXYI2wAAAAJ&amp;hl=en">Shangyu
                                    Xie</a>, <a href="https://sites.google.com/view/ashishkundu/home/">Ashish Kundu</a>,
                                <a href="https://scholar.google.com/citations?user=9rHwD8wAAAAJ&hl=en">Ali Payani</a>,
                                <a href="https://yhongcs.github.io/index.html">Yuan Hong</a>, <a
                                    href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>.
                                <br /> <em>Workshop in the 36th Conference on Neural Information Processing Systems 
                                    ( <strong><a href="https://tsrml2022.github.io/" style="text-decoration:none"><font color="#494e52">TSRML@NeurIPS 2022</font></a>
                                    </strong> and <strong><a href="https://www.afciworkshop.org/afcp2022" style="text-decoration:none"><font color="#494e52">AFCP@NeurIPS 2022</font></a></strong> )</em>.
                                <br /> <a href="https://arxiv.org/abs/2207.08336">[arXiv]</a>
                                <a
                                    href="https://recorder-v3.slideslive.com/?share=78276&s=d4483c12-ab9f-42ec-953d-da838d9cd163">[Video]</a>
                                <a
                                    href="https://drive.google.com/file/d/1i3tYxj0DWVnBFDGxV0iP2H_-plb7lVD-/view?usp=share_link">[Slides]</a>
                                <a
                                    href="https://drive.google.com/file/d/1Wbi3SDY4cq5Kb1XYS_oWDGZPWMeH2zdQ/view?usp=share_link">[Poster]</a>
                                <!-- <a href="https://drive.google.com/file/d/1Kuv07fWHQ5jgAqL60CXIKXds0f3bTV0T/view?usp=share_link">[TSRML version]</a>  -->
                                <!-- <a href="https://drive.google.com/file/d/1XGJA5GR-q07d3bsQWZJV7uVpqAa_86mM/view?usp=share_link">[AFCP version]</a></p> -->
                                <br /> <strong>
                                    <font color="#3b5af2">Media Coverage</font>
                                </strong> : <a
                                    href="https://www.iit.edu/student-experience/student-and-alumni-stories/breaking-biases">[Illinois
                                    Tech News]</a>.</em><br />
                        </li>


                        <li>
                            <p><strong><a href="https://www.mdpi.com/1999-4893/15/9/299" style="text-decoration:none"><font color="#494e52">Artificial Intelligence Algorithms for Treatment of Diabetes.</font></a></strong><br /> <a
                                    href="https://scholar.google.com/citations?user=F3OZmPoAAAAJ&amp;hl=en">Mudassir M.
                                    Rashid</a>, <a
                                    href="https://scholar.google.com/citations?user=njl6K6VfGlAC&amp;hl=en">Mohammad
                                    Reza Askari</a>, <strong>Canyu Chen</strong>, <a
                                    href="https://yueqingliang1.github.io/">Yueqing Liang</a>, <a
                                    href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>, <a
                                    href="https://sites.google.com/iit.edu/ali-cinar">Ali Cinar</a>.<br />
                                <strong><em>
                                        <font color="#494e52">Algorithms 2022</font>
                                    </em></strong>.<br /> <a href="https://www.mdpi.com/1999-4893/15/9/299">[Paper]</a>
                            </p>
                        </li>

                        <li>
                            <p><strong><a href="https://arxiv.org/abs/2206.10071" style="text-decoration:none"><font color="#494e52">BOND: Benchmarking Unsupervised Outlier Node Detection on Static Attributed
                                    Graphs.</font></a></strong><br />
                                Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang, Kaize Ding,
                                <strong>Canyu Chen</strong>, Hao Peng, Kai Shu, Lichao Sun, Jundong Li, George H. Chen,
                                Zhihao Jia, Philip S. Yu.
                                <br /> <em>Proceedings of the 36th Conference on Neural Information Processing Systems (<strong>
                                        <font color="#494e52">NeurIPS 2022</font>
                                    </strong>), Datasets and Benchmarks Track</em>.
                                <br /> 
                                <a href="https://arxiv.org/abs/2206.10071">[arXiv]</a>
                                <a href="https://github.com/pygod-team/pygod">[code]</a>

                            </p>
                        </li>

                    </ul>
                    <h2 id="talks">Talks</h2>
                    <ul>
                        <li>
                            <p>[04/18/2023] <strong>Fairness in AI: An Introduction</strong> at UIC
                                <a
                                    href="https://drive.google.com/file/d/1U9CkO_nOTKDJP1DycKrYW2r0IugXLjqh/view?usp=sharing">[Slides]</a>
                                <br />
                        </li>
                    </ul>
                </section>
                <footer class="page__meta"></footer>
            </div>
        </article>
    </div>
    <div class="page__footer">
        <footer></footer>
    </div>
    <script src="https://yueqingliang1.github.io/assets/js/main.min.js"></script>
    <script> (function (i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () { (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date(); a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m) })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script>


    <!-- Statcounter code for homepage https://canyuchen.com/ on
Google Sites (new) -->
    <script type="text/javascript">
        var sc_project = 12925672;
        var sc_invisible = 1;
        var sc_security = "fc1d0147"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/12925672/0/fc1d0147/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->
</body>

</html>